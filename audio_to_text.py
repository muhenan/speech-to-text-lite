#!/usr/bin/env python3
"""
ç®€å•çš„éŸ³é¢‘æ–‡ä»¶è½¬æ–‡å­—å·¥å…·
æ”¯æŒ MP4, WAV, MP3 ç­‰å¸¸è§éŸ³é¢‘æ ¼å¼
"""

import sys
import os
from pathlib import Path
from faster_whisper import WhisperModel
from pydub import AudioSegment
import numpy as np
import time

def convert_audio_to_text(audio_file_path, model_size="tiny", language="zh"):
    """
    å°†éŸ³é¢‘æ–‡ä»¶è½¬æ¢ä¸ºæ–‡å­—

    Args:
        audio_file_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        model_size: Whisperæ¨¡å‹å¤§å° ("tiny", "base", "small", "medium", "large-v3")
        language: è¯­è¨€ä»£ç  ("zh"=ä¸­æ–‡, "en"=è‹±æ–‡, None=è‡ªåŠ¨æ£€æµ‹)
    """

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(audio_file_path):
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ '{audio_file_path}' ä¸å­˜åœ¨")
        return

    print(f"ğŸµ æ­£åœ¨å¤„ç†éŸ³é¢‘æ–‡ä»¶: {audio_file_path}")
    print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_size}")
    print(f"ğŸŒ è¯­è¨€è®¾ç½®: {language if language else 'è‡ªåŠ¨æ£€æµ‹'}")
    print("-" * 50)

    try:
        # åŠ è½½Whisperæ¨¡å‹
        print("â³ æ­£åœ¨åŠ è½½Whisperæ¨¡å‹...")
        model = WhisperModel(model_size, device="cpu")
        print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")

        # è¯»å–å¹¶å¤„ç†éŸ³é¢‘æ–‡ä»¶
        print("â³ æ­£åœ¨è¯»å–éŸ³é¢‘æ–‡ä»¶...")
        audio = AudioSegment.from_file(audio_file_path)

        # è½¬æ¢ä¸ºWhisperéœ€è¦çš„æ ¼å¼
        audio = audio.set_frame_rate(16000).set_channels(1)

        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        samples = np.array(audio.get_array_of_samples(), dtype=np.float32)
        if audio.sample_width == 2:  # 16-bit
            samples = samples / 32768.0
        elif audio.sample_width == 4:  # 32-bit
            samples = samples / 2147483648.0

        print(f"ğŸ“Š éŸ³é¢‘ä¿¡æ¯: æ—¶é•¿ {len(audio)/1000:.1f}ç§’, é‡‡æ ·ç‚¹ {len(samples)}")
        print("âœ… éŸ³é¢‘å¤„ç†å®Œæˆ")

        # å¼€å§‹è½¬å½•
        print("â³ æ­£åœ¨è¿›è¡Œè¯­éŸ³è½¬æ–‡å­—...")
        start_time = time.time()

        segments, info = model.transcribe(
            samples,
            language=language,
            beam_size=5,
            best_of=5,
            temperature=0.0
        )

        # è¾“å‡ºç»“æœ
        print("ğŸ¯ è½¬å½•ç»“æœ:")
        print("=" * 50)

        full_text = ""
        for segment in segments:
            timestamp = f"[{segment.start:.1f}s - {segment.end:.1f}s]"
            text = segment.text.strip()
            print(f"{timestamp} {text}")
            full_text += text + " "

        print("=" * 50)
        print(f"ğŸ“ å®Œæ•´æ–‡å­—: {full_text.strip()}")

        end_time = time.time()
        print(f"â±ï¸  å¤„ç†æ—¶é—´: {end_time - start_time:.1f}ç§’")
        print(f"ğŸ›ï¸  æ£€æµ‹è¯­è¨€: {info.language}")
        print(f"ğŸ“Š è¯­è¨€æ¦‚ç‡: {info.language_probability:.2%}")

        # ä¿å­˜åˆ°æ–‡ä»¶
        output_file = Path(audio_file_path).stem + "_transcript.txt"
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(f"éŸ³é¢‘æ–‡ä»¶: {audio_file_path}\n")
            f.write(f"å¤„ç†æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"æ£€æµ‹è¯­è¨€: {info.language} ({info.language_probability:.2%})\n")
            f.write(f"æ¨¡å‹: {model_size}\n")
            f.write("-" * 50 + "\n\n")

            for segment in segments:
                timestamp = f"[{segment.start:.1f}s - {segment.end:.1f}s]"
                f.write(f"{timestamp} {segment.text.strip()}\n")

            f.write("\n" + "=" * 50 + "\n")
            f.write(f"å®Œæ•´æ–‡å­—:\n{full_text.strip()}")

        print(f"ğŸ’¾ è½¬å½•ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤ éŸ³é¢‘è½¬æ–‡å­—å·¥å…·")
    print("æ”¯æŒæ ¼å¼: MP4, MP3, WAV, M4A ç­‰")
    print()

    if len(sys.argv) < 2:
        print("ç”¨æ³•:")
        print("  python audio_to_text.py <éŸ³é¢‘æ–‡ä»¶è·¯å¾„> [æ¨¡å‹å¤§å°] [è¯­è¨€]")
        print()
        print("ç¤ºä¾‹:")
        print("  python audio_to_text.py audio.mp4")
        print("  python audio_to_text.py audio.mp4 small")
        print("  python audio_to_text.py audio.mp4 base en")
        print()
        print("æ¨¡å‹å¤§å°: tiny(æœ€å¿«) < base < small < medium < large-v3(æœ€å‡†ç¡®)")
        print("è¯­è¨€ä»£ç : zh(ä¸­æ–‡), en(è‹±æ–‡), ç•™ç©ºè‡ªåŠ¨æ£€æµ‹")
        return

    audio_file = sys.argv[1]
    model_size = sys.argv[2] if len(sys.argv) > 2 else "tiny"
    language = sys.argv[3] if len(sys.argv) > 3 else "zh"

    # å¦‚æœè¯­è¨€å‚æ•°æ˜¯"auto"ï¼Œåˆ™è®¾ä¸ºNoneè®©æ¨¡å‹è‡ªåŠ¨æ£€æµ‹
    if language.lower() in ["auto", "none", "detect"]:
        language = None

    convert_audio_to_text(audio_file, model_size, language)

if __name__ == "__main__":
    main()